# Base inference configuration template
# This will be used as a template for each checkpoint evaluation

# Base directories
base_data_dir: "/mnt/data/COMBINED"
output_path: "PLACEHOLDER_OUTPUT_PATH"  # Will be replaced by batch script
weight_path: "PLACEHOLDER_WEIGHT_PATH"  # Will be replaced by batch script

# Dataset configuration
SolO: "false"
Stereo: "false"

# Model configuration
model: "vit"  # Options: "vit", "hybrid", "vitpatch", "fusion"
wavelengths: [94, 131, 171, 193, 211, 304]  # AIA wavelengths in Angstroms

# MC Dropout configuration
mc:
  active: "false"
  runs: 5

# SolO data configuration (if using SolO dataset)
SolO_data:
  solo_img_dir: "/mnt/data/ML-Ready_clean/SolO/SolO/ML-Ready-SolO"
  sxr_dir: "${base_data_dir}/SXR"
  sxr_norm_path: "${base_data_dir}/SolO/SXR/normalized_sxr.npy"

# Stereo data configuration (if using Stereo dataset)
Stereo_data:
  stereo_img_dir: "/mnt/data/ML-Ready-mixed/STEREO_processed"
  sxr_dir: "/mnt/data/ML-Ready-mixed/ML-Ready-mixed/SXR"
  sxr_norm_path: "/mnt/data/ML-READY/SXR/normalized_sxr.npy"

# Model parameters
model_params:
  input_size: 512
  patch_size: 16
  batch_size: 16
  no_weights: false  # Set to true to skip saving attention weights

# Model architecture parameters (should match training config)
vit_custom:
  embed_dim: 512
  num_channels: 6
  num_classes: 1
  patch_size: 16
  num_patches: 4096
  hidden_dim: 512
  num_heads: 16
  num_layers: 3
  dropout: 0.1

# Data paths
data:
  aia_dir: "${base_data_dir}/AIA-SPLIT/"
  sxr_dir: "${base_data_dir}/SXR-SPLIT/"
  sxr_norm_path: "${base_data_dir}/SXR-SPLIT/normalized_sxr.npy"
  checkpoint_path: "PLACEHOLDER_CHECKPOINT_PATH"  # Will be replaced by batch script

# MEGSAI parameters (should match training config)
megsai:
  cnn_model: "updated"
  cnn_dp: 0.2
  weight_decay: 1e-5
  cosine_restart_T0: 50
  cosine_restart_Tmult: 2
  cosine_eta_min: 1e-7

# Fusion parameters (if using fusion model)
fusion:
  scalar_branch: "hybrid"
  lr: 0.0001
  lambda_vit_to_target: 0.3
  lambda_scalar_to_target: 0.1
  learnable_gate: true
  gate_init_bias: 5.0
  scalar_kwargs:
    d_input: 6
    d_output: 1
    cnn_model: "updated"
    cnn_dp: 0.75
